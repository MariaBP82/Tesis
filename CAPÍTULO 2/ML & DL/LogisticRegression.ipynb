{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82697559-f1f0-4990-adbf-14f147fb08a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Error cuadrático medio (MSE) en test: 0.1336\n",
      "\n",
      "Resumen de resultados (ordenados por MSE):\n",
      "   param_C param_penalty  mean_MSE   std_MSE\n",
      "6        1            l1    0.2000  0.023717\n",
      "7        1            l2    0.2000  0.023717\n",
      "8       10            l1    0.2000  0.023717\n",
      "9       10            l2    0.2000  0.023717\n",
      "10     100            l1    0.2025  0.025495\n",
      "11     100            l2    0.2025  0.025495\n",
      "5      0.1            l2    0.2050  0.030208\n",
      "4      0.1            l1    0.2275  0.022913\n",
      "3     0.01            l2    0.2550  0.024495\n",
      "2     0.01            l1    0.2600  0.014577\n",
      "1    0.001            l2    0.2750  0.007906\n",
      "0    0.001            l1    0.6900  0.005000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Simular datos\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "X1 = np.random.normal(0, 1, n)\n",
    "X2 = np.random.normal(2, 1.5, n)\n",
    "logits = -1 + 0.8 * X1 + 1.2 * X2\n",
    "prob = 1 / (1 + np.exp(-logits))\n",
    "y = np.random.binomial(1, prob)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
    "X = df[['X1', 'X2']]\n",
    "y = df['y']\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir grid de hiperparámetros\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# Inicializar modelo y GridSearchCV\n",
    "logreg = LogisticRegression()\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo y predicciones\n",
    "best_model = grid_search.best_estimator_\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluación con MSE\n",
    "mse = mean_squared_error(y_test, y_prob)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(f\"Error cuadrático medio (MSE) en test: {mse:.4f}\\n\")\n",
    "\n",
    "# Mostrar todos los resultados del grid\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results = results[['param_C', 'param_penalty', 'mean_test_score', 'std_test_score']]\n",
    "results['mean_test_score'] = -results['mean_test_score']  # Convertimos a MSE positivo\n",
    "results = results.rename(columns={'mean_test_score': 'mean_MSE', 'std_test_score': 'std_MSE'})\n",
    "\n",
    "print(\"Resumen de resultados (ordenados por MSE):\")\n",
    "print(results.sort_values(by='mean_MSE'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d51cf0-82ac-450a-abdc-5eb8bcd8413c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
